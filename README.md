# Lane Detection Using Image Processing

This project involves implementing lane detection using various image processing techniques. The main focus is on enhancing the image quality and identifying lane boundaries in images and video datasets. The project uses techniques like noise reduction, contrast enhancement, segmentation, edge detection, and thresholding.

**Team Members:**  
Fares Hazem  
Peter Hany  

**Instructors:**  
Dr. Mahmoud Gamal  
Eng. Amany  

## Table of Contents

1. [Introduction](#introduction)
2. [Project Overview](#project-overview)
3. [Technologies Used](#technologies-used)
4. [Results](#results)
5. [File Structure](#file-structure)

## Introduction

Lane detection is an essential task in autonomous driving systems. In this project, we focused on implementing a lane detection pipeline using classic image processing techniques. The goal is to extract the lane boundaries from images and video streams for applications in self-driving cars.

## Project Overview

The project implements several steps for detecting lanes in images and video:
- **Noise Reduction**: Reducing noise using Gaussian Blur and other filters.
- **Contrast Enhancement**: Enhancing image contrast to improve lane visibility.
- **Segmentation**: Applying various thresholding methods (Simple, Global, Adaptive, Otsu) and region-based methods (Clustering, Growth Region, Split & Merge).
- **Edge Detection**: Using Sobel, Prewitt, and Canny edge detection algorithms.

The dataset used includes a variety of images taken from the **Carla dataset** and videos found online.

## Technologies Used

- Python
- OpenCV
- Numpy
- Matplotlib
- Image Processing Techniques
- GitHub (for version control)

## Results

The results of the project include the detection of lane boundaries in various images and videos. The following figures show the lane detection results:

- **HSV Thresholding**: Achieved the best results.
- **Original Image with Keypoints**: Visualized key points on the original image.
- **Birdseye Image**: Shows the transformed birdseye view.
- **Thresholded Output**: The final output after thresholding.

## File Structure

The project directory is organized as follows:

```
Image-Processing-Final-Project/
│
├── Images/                    # Folder for storing additional images
│
├── Lane Detection/            # Main folder for the lane detection project
│   ├── Code/                  # Contains the code scripts
│   │   ├── Adjust Image Thresholds.py
│   │   └── LaneDetection.py
│   ├── Input/                 # Input files for the project
│   │   ├── image.jpg
│   │   └── LaneVideo.mp4
│   └── Output/                # Output files generated by the scripts
│   │   ├── output_birdseye.avi
│   │   └── output_original.avi
│   │   └── output_thresholded.avi
├── Notebook/                  # Jupyter notebooks for experimentation
│   │   └── image-processing-final-project.ipynb
├── Report/                    # Documentation and project reports
│   │   ├── Image Processing Final Project.pdf
│   │   ├── Image Processing Final Project.tex
```

- **Code/**: Contains the Python scripts for the lane detection process. 
  - `Adjust Image Thresholds.py`: Script for experimenting with image threshold adjustments.
  - `LaneDetection.py`: Main script for performing lane detection on images and videos.

- **Input/**: Stores input data, such as images and video files for processing. For example:
  - `image.jpg`: A sample image for lane detection.
  - `LaneVideo.mp4`: A video file demonstrating lane detection.

- **Output/**: Contains the output images and videos after processing.

- **Images/**: Additional images used in the project for demonstrations.

- **Notebook/**: Folder for Jupyter notebooks used for testing and prototyping different parts of the pipeline.

- **Report/**: Contains documentation, reports, and presentations related to the project.
